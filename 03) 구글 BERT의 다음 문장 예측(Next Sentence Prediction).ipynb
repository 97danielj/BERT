{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615f6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForNextSentencePrediction\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eae2c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForNextSentencePrediction.\n",
      "\n",
      "All the layers of TFBertForNextSentencePrediction were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771839e",
   "metadata": {},
   "source": [
    "## 2. BERT의 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d0f3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b53cf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 문장 정수 인코딩\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d81b895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1999  3304  1010 10733  2366  1999  5337 10906  1010  2107  2004\n",
      "   2012  1037  4825  1010  2003  3591  4895 14540  6610  2094  1012   102\n",
      "  10733  2003  8828  2007  1996  2224  1997  1037  5442  1998  9292  1012\n",
      "   1999 10017 10906  1010  2174  1010  2009  2003  3013  2046 17632  2015\n",
      "   2000  2022  8828  2096  2218  1999  1996  2192  1012   102]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "501555fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] : 101\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "852d1e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 위의 정수 인코딩 결과를 다시 디코딩해보면 현재 입력의 구성을 확인할 수 있습니다.\n",
    "print(tokenizer.decode(encoding['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e52f6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934e70f",
   "metadata": {},
   "source": [
    "0이 연속적으로 등장하다가 어느 순간부터 1이 연속적으로 등장하는데, 이는 [CLS] 토큰의 위치부터 첫번째 문장이 끝나고나서 등장한 [SEP] 토큰까지의 위치에는 0이 등장하고, 다음 두번째 문장부터는 1이 등장하는 것입니다. token_type_ids에서는 0과 1로 두 개의 문장을 구분하고 있습니다.\n",
    "즉, 0은 sentence 0임베딩, 1은 setence 1임베딩이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226eaa43",
   "metadata": {},
   "source": [
    "## 3. 다음 문장 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce2f7dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.9999714e-01 2.8381858e-06]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08386472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [0]\n"
     ]
    }
   ],
   "source": [
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19593967",
   "metadata": {},
   "source": [
    "이는 BERT가 다음 문장 예측을 학습했을 당시에 실질적으로 이어지는 두 개의 문장의 레이블은 0. 이어지지 않는 두 개의 문장의 경우에는 레이블을 1로 두고서 이진 분류로 학습을 하였기 때문입니다.\n",
    "그래서 레이블값이 인덱스 위치로 간다음 분류에대한 확률 값을 저장시키낟."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a75290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
