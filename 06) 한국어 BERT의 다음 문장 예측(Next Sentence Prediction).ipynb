{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b965975",
   "metadata": {},
   "source": [
    "# 1. 다음 문장 예측 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c095884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForNextSentencePrediction\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4e012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForNextSentencePrediction: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('klue/bert-base', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5a714",
   "metadata": {},
   "source": [
    "## 2. 다음 문장 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405e5bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [0]\n"
     ]
    }
   ],
   "source": [
    "# 이어지는 두 개의 문장\n",
    "prompt = \"2002년 월드컵 축구대회는 일본과 공동으로 개최되었던 세계적인 큰 잔치입니다.\"\n",
    "next_sentence = \"여행을 가보니 한국의 2002년 월드컵 축구대회의 준비는 완벽했습니다.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "\n",
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0655df59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[9.9988782e-01, 1.1218969e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68db7492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [1]\n"
     ]
    }
   ],
   "source": [
    "# 상관없는 두 개의 문장\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "\n",
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
